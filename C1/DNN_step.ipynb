{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXQE2lTjyjR5p2muh6hCHX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qzSxmLzlwNOx","executionInfo":{"status":"ok","timestamp":1698931611517,"user_tz":-390,"elapsed":443,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"outputs":[],"source":["import numpy as np\n","\n","def sigmoid(Z):\n","\n","\n","    A = 1/(1+np.exp(-Z))\n","    cache = Z\n","\n","    return A, cache\n","\n","def relu(Z):\n","\n","\n","    A = np.maximum(0,Z)\n","\n","    assert(A.shape == Z.shape)\n","\n","    cache = Z\n","    return A, cache\n","\n","\n","def relu_backward(dA, cache):\n","\n","\n","    Z = cache\n","    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n","\n","    # When z <= 0, you should set dz to 0 as well.\n","    dZ[Z <= 0] = 0\n","\n","    assert (dZ.shape == Z.shape)\n","\n","    return dZ\n","\n","def sigmoid_backward(dA, cache):\n","\n","\n","    Z = cache\n","\n","    s = 1/(1+np.exp(-Z))\n","    dZ = dA * s * (1-s)\n","\n","    assert (dZ.shape == Z.shape)\n","\n","    return dZ\n","\n"]},{"cell_type":"code","source":["import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","\n","import copy\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","np.random.seed(1)"],"metadata":{"id":"U6FyOU9TweSB","executionInfo":{"status":"ok","timestamp":1698931634076,"user_tz":-390,"elapsed":4,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def initialize_parameters(n_x, n_h, n_y):\n","\n","\n","    np.random.seed(1)\n","\n","\n","    # YOUR CODE STARTS HERE\n","\n","    W1 = np.random.randn(n_h,n_x) * 0.01\n","    b1 = np.zeros((n_h,1))\n","    W2 = np.random.randn(n_y,n_h) * 0.01\n","    b2 = np.zeros((n_y,1))\n","\n","\n","    # YOUR CODE ENDS HERE\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","\n","    return parameters"],"metadata":{"id":"Uyk6bKCiQ9Jy","executionInfo":{"status":"ok","timestamp":1698931697002,"user_tz":-390,"elapsed":485,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"58ih1EiUQ_Ml","executionInfo":{"status":"ok","timestamp":1698915831201,"user_tz":-390,"elapsed":7,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def initialize_parameters_deep(layer_dims):\n","\n","\n","    np.random.seed(3)\n","    parameters = {}\n","    L = len(layer_dims) # number of layers in the network\n","\n","    for l in range(1, L):\n","\n","        # YOUR CODE STARTS HERE\n","        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n","        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n","        # YOUR CODE ENDS HERE\n","\n","        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n","        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n","\n","\n","    return parameters"],"metadata":{"id":"4gimRbADwxIZ","executionInfo":{"status":"ok","timestamp":1698931977271,"user_tz":-390,"elapsed":5,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["testA = np.array([[1,2,3],[2,3,4]])\n","print(testA)\n","print(testA.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJZzCwPB0GTh","executionInfo":{"status":"ok","timestamp":1698931999201,"user_tz":-390,"elapsed":6,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"7f4960ea-3be0-4d1a-8a2d-a227e2b25a74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3]\n"," [2 3 4]]\n","(2, 3)\n"]}]},{"cell_type":"code","source":["assert (testA.shape == (2,3))\n"],"metadata":{"id":"7dFsYf9lz8VO","executionInfo":{"status":"ok","timestamp":1698932041858,"user_tz":-390,"elapsed":529,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","def linear_forward(A, W, b):\n","\n","\n","\n","    # YOUR CODE STARTS HERE\n","    Z = np.dot(W,A) + b\n","\n","    # YOUR CODE ENDS HERE\n","    cache = (A, W, b)\n","\n","    return Z, cache"],"metadata":{"id":"Dz5U9gnTxF8d","executionInfo":{"status":"ok","timestamp":1698932139379,"user_tz":-390,"elapsed":485,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def linear_activation_forward(A_prev, W, b, activation):\n","\n","\n","    if activation == \"sigmoid\":\n","\n","        # YOUR CODE STARTS HERE\n","        Z, linear_cache = linear_forward(A_prev, W, b)\n","        A, activation_cache = sigmoid(Z)\n","        # YOUR CODE ENDS HERE\n","\n","    elif activation == \"relu\":\n","\n","        # YOUR CODE STARTS HERE\n","        Z, linear_cache = linear_forward(A_prev, W, b)\n","        A, activation_cache = relu(Z)\n","\n","        # YOUR CODE ENDS HERE\n","    cache = (linear_cache, activation_cache)\n","\n","    return A, cache"],"metadata":{"id":"FrX81sOaxMJe","executionInfo":{"status":"ok","timestamp":1698932297428,"user_tz":-390,"elapsed":340,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def L_model_forward(X, parameters):\n","\n","\n","    caches = []\n","    A = X\n","    L = len(parameters) // 2                  # number of layers in the neural network\n","\n","    # The for loop starts at 1 because layer 0 is the input\n","    for l in range(1, L):\n","        A_prev = A\n","\n","        # YOUR CODE STARTS HERE\n","        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], activation = \"relu\")\n","        caches.append(cache)\n","        # YOUR CODE ENDS HERE\n","\n","\n","    # YOUR CODE STARTS HERE\n","    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], activation = \"sigmoid\")\n","    caches.append(cache)\n","    # YOUR CODE ENDS HERE\n","\n","    return AL, caches"],"metadata":{"id":"PWHfi7b3xbvO","executionInfo":{"status":"ok","timestamp":1698932770358,"user_tz":-390,"elapsed":328,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def compute_cost(AL, Y):\n","\n","\n","    m = Y.shape[1]\n","\n","\n","    # YOUR CODE STARTS HERE\n","    cost = (np.dot(Y,np.log(AL.T)) + np.dot((1-Y),np.log(1-AL.T)))/(-m)\n","\n","    # YOUR CODE ENDS HERE\n","\n","    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n","\n","\n","    return cost"],"metadata":{"id":"fnsG3Ovoxkp5","executionInfo":{"status":"ok","timestamp":1698933092317,"user_tz":-390,"elapsed":331,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["A = np.array([[1, 2], [3, 4]])\n","A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcmAwl-4Td4W","executionInfo":{"status":"ok","timestamp":1698933114230,"user_tz":-390,"elapsed":596,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"a04de88f-9e01-43dc-c291-ff5ccc12daa2"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2],\n","       [3, 4]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["A = np.array([[1, 2], [3, 4]])\n","\n","print('axis=1 and keepdims=True')\n","print(np.sum(A, axis=1, keepdims=True))\n","print('axis=1 and keepdims=False')\n","print(np.sum(A, axis=1, keepdims=False))\n","print('axis=0 and keepdims=True')\n","print(np.sum(A, axis=0, keepdims=True))\n","print('axis=0 and keepdims=False')\n","print(np.sum(A, axis=0, keepdims=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpkFSPNfxm6y","executionInfo":{"status":"ok","timestamp":1698933237169,"user_tz":-390,"elapsed":379,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"5b91abbd-f828-4807-c774-a10386a9bb7e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["axis=1 and keepdims=True\n","[[3]\n"," [7]]\n","axis=1 and keepdims=False\n","[3 7]\n","axis=0 and keepdims=True\n","[[4 6]]\n","axis=0 and keepdims=False\n","[4 6]\n"]}]},{"cell_type":"code","source":["def linear_backward(dZ, cache):\n","\n","    A_prev, W, b = cache\n","    m = A_prev.shape[1]\n","\n","\n","    # YOUR CODE STARTS HERE\n","    dW = np.dot(dZ,A_prev.T)/m\n","    db = np.sum(dZ, axis=1,keepdims=True)/m\n","    dA_prev = np.dot(W.T,dZ)\n","\n","    # YOUR CODE ENDS HERE\n","\n","    return dA_prev, dW, db"],"metadata":{"id":"xhrsrWS_xtPD","executionInfo":{"status":"ok","timestamp":1698933507417,"user_tz":-390,"elapsed":377,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def linear_activation_backward(dA, cache, activation):\n","\n","    linear_cache, activation_cache = cache\n","\n","    if activation == \"relu\":\n","\n","        # YOUR CODE STARTS HERE\n","        dZ = relu_backward(dA, activation_cache)\n","        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n","        # YOUR CODE ENDS HERE\n","\n","    elif activation == \"sigmoid\":\n","\n","        # YOUR CODE STARTS HERE\n","        dZ = sigmoid_backward(dA, activation_cache)\n","        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n","        # YOUR CODE ENDS HERE\n","\n","    return dA_prev, dW, db"],"metadata":{"id":"SPFnXVqNx2W6","executionInfo":{"status":"ok","timestamp":1698933690354,"user_tz":-390,"elapsed":393,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def L_model_backward(AL, Y, caches):\n","\n","    grads = {}\n","    L = len(caches) # the number of layers\n","    m = AL.shape[1]\n","    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n","\n","\n","    # YOUR CODE STARTS HERE\n","    dAL =  - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n","\n","    # YOUR CODE ENDS HERE\n","\n","\n","    # YOUR CODE STARTS HERE\n","    current_cache = caches[L-1]\n","    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, activation=\"sigmoid\")\n","    grads[\"dA\" + str(L-1)] = dA_prev_temp\n","    grads[\"dW\" + str(L)] = dW_temp\n","    grads[\"db\" + str(L)] = db_temp\n","    # YOUR CODE ENDS HERE\n","\n","    # Loop from l=L-2 to l=0\n","    for l in reversed(range(L-1)):\n","\n","        # YOUR CODE STARTS HERE\n","        current_cache = caches[l]\n","        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation=\"relu\")\n","        grads[\"dA\" + str(l)] = dA_prev_temp\n","        grads[\"dW\" + str(l+1)] = dW_temp\n","        grads[\"db\" + str(l+1)] = db_temp\n","\n","        # YOUR CODE ENDS HERE\n","\n","    return grads"],"metadata":{"id":"wMCuS2Tux_Rk","executionInfo":{"status":"ok","timestamp":1698934274015,"user_tz":-390,"elapsed":361,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def update_parameters(params, grads, learning_rate):\n","\n","    parameters = copy.deepcopy(params)\n","    L = len(parameters) // 2 # number of layers in the neural network\n","\n","    #(≈ 2 lines of code)\n","    for l in range(L):\n","\n","        # YOUR CODE STARTS HERE\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * grads[\"dW\" + str(l+1)])\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * grads[\"db\" + str(l+1)])\n","        # YOUR CODE ENDS HERE\n","    return parameters"],"metadata":{"id":"err_c1toyJGX","executionInfo":{"status":"ok","timestamp":1698934323740,"user_tz":-390,"elapsed":4,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PgZ7Y11ayTi4","executionInfo":{"status":"ok","timestamp":1698915831577,"user_tz":-390,"elapsed":4,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":25,"outputs":[]}]}