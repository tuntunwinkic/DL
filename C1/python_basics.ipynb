{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0Z0LwNo2/15H5LAjRl6fx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"zqQqR16L3e5c","executionInfo":{"status":"ok","timestamp":1697119186096,"user_tz":-390,"elapsed":3,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"outputs":[],"source":["test = \"Hello World\"\n"]},{"cell_type":"code","source":["print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkfZMVvw3jOd","executionInfo":{"status":"ok","timestamp":1697119187884,"user_tz":-390,"elapsed":5,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"a3c21c67-c04c-425f-e625-4e069adb20bd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World\n"]}]},{"cell_type":"code","source":["import math\n","\n","\n","def basic_sigmoid(x):\n","\n","\n","    s = 1/(1+math.exp(-x))\n","\n","\n","    return s"],"metadata":{"id":"ldWgNqbF3kKn","executionInfo":{"status":"ok","timestamp":1697119214577,"user_tz":-390,"elapsed":386,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(\"basic_sigmoid(1) = \" + str(basic_sigmoid(1)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZltpJcoF3rGj","executionInfo":{"status":"ok","timestamp":1697119307131,"user_tz":-390,"elapsed":333,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"76c3b1a1-8b96-4a32-bf9a-b4c9f52e64e4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["basic_sigmoid(1) = 0.7310585786300049\n"]}]},{"cell_type":"code","source":["x = [1, 2, 3] # x becomes a python list object\n","basic_sigmoid(x) # you will see this give an error when you run it, because x is a vector."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"I6Jq-iyo3t2u","executionInfo":{"status":"error","timestamp":1697119319723,"user_tz":-390,"elapsed":9,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"29b5684a-9054-4ede-d77e-676ee596b140"},"execution_count":6,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d845b0f01fb2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# x becomes a python list object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbasic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# you will see this give an error when you run it, because x is a vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-07ea12afbdd5>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"]}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"Y3Ibz5U637s7","executionInfo":{"status":"ok","timestamp":1697119335226,"user_tz":-390,"elapsed":336,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","def sigmoid(x):\n","\n","    s=1/(1+np.exp(-x))\n","\n","\n","    return s"],"metadata":{"id":"kmfeSx1F3xZq","executionInfo":{"status":"ok","timestamp":1697119420847,"user_tz":-390,"elapsed":332,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["t_x = np.array([1, 2, 3])\n","print(\"sigmoid(t_x) = \" + str(sigmoid(t_x)))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrEHNZAa39MH","executionInfo":{"status":"ok","timestamp":1697119428299,"user_tz":-390,"elapsed":3,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"0879455c-c448-4178-faa9-056ccc8462f8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["sigmoid(t_x) = [0.73105858 0.88079708 0.95257413]\n"]}]},{"cell_type":"markdown","source":["<a name='1-2'></a>\n","### 1.2 - Sigmoid Gradient\n","\n","As you've seen in lecture, you will need to compute gradients to optimize loss functions using backpropagation. Let's code your first gradient function.\n","\n","<a name='ex-4'></a>\n","### Exercise 4 - sigmoid_derivative\n","Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is:\n","\n","$$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n","\n","You often code this function in two steps:\n","1. Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.\n","2. Compute $\\sigma'(x) = s(1-s)$"],"metadata":{"id":"t0MOS8wK4NAl"}},{"cell_type":"code","source":["\n","def sigmoid_derivative(x):\n","\n","    s = sigmoid(x)\n","    ds = s*(1-s)\n","\n","\n","    return ds"],"metadata":{"id":"363JxoUN4Az4","executionInfo":{"status":"ok","timestamp":1697119543200,"user_tz":-390,"elapsed":353,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["t_x = np.array([1, 2, 3])\n","print (\"sigmoid_derivative(t_x) = \" + str(sigmoid_derivative(t_x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HineajI4G8q","executionInfo":{"status":"ok","timestamp":1697119550397,"user_tz":-390,"elapsed":361,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"3ed8311a-db3d-477a-abed-b5f3fb8cb601"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["sigmoid_derivative(t_x) = [0.19661193 0.10499359 0.04517666]\n"]}]},{"cell_type":"code","source":["def image2vector(image):\n","\n","    v = image.reshape((image.shape[0] * image.shape[1]* image.shape[2]),1)\n","\n","\n","    return v"],"metadata":{"id":"J6SIRCdI4SmA","executionInfo":{"status":"ok","timestamp":1697119683635,"user_tz":-390,"elapsed":724,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["t_image = np.array([[[ 0.67826139,  0.29380381],\n","                     [ 0.90714982,  0.52835647],\n","                     [ 0.4215251 ,  0.45017551]],\n","\n","                   [[ 0.92814219,  0.96677647],\n","                    [ 0.85304703,  0.52351845],\n","                    [ 0.19981397,  0.27417313]],\n","\n","                   [[ 0.60659855,  0.00533165],\n","                    [ 0.10820313,  0.49978937],\n","                    [ 0.34144279,  0.94630077]]])\n","\n","print(t_image.shape)\n","print (\"image2vector(image) = \" + str(image2vector(t_image)))\n","a= image2vector(t_image)\n","print(a.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIBj9dHu4YDw","executionInfo":{"status":"ok","timestamp":1697119698401,"user_tz":-390,"elapsed":405,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"425b9d90-fe6c-4f03-bc7c-9384713cc726"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(3, 3, 2)\n","image2vector(image) = [[0.67826139]\n"," [0.29380381]\n"," [0.90714982]\n"," [0.52835647]\n"," [0.4215251 ]\n"," [0.45017551]\n"," [0.92814219]\n"," [0.96677647]\n"," [0.85304703]\n"," [0.52351845]\n"," [0.19981397]\n"," [0.27417313]\n"," [0.60659855]\n"," [0.00533165]\n"," [0.10820313]\n"," [0.49978937]\n"," [0.34144279]\n"," [0.94630077]]\n","(18, 1)\n"]}]},{"cell_type":"code","source":["\n","def normalize_rows(x):\n","\n","    x_norm = np.linalg.norm(x, axis=1, keepdims=True) # find the norm on axis 1, for all columns on the same row\n","\n","    x = x/x_norm\n","\n","    return x"],"metadata":{"id":"8FIe28W74cE4","executionInfo":{"status":"ok","timestamp":1697119906714,"user_tz":-390,"elapsed":334,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["x = np.array([[0, 3, 4],\n","              [1, 6, 4]])\n","print(\"normalizeRows(x) = \" + str(normalize_rows(x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTHJpjHs41VV","executionInfo":{"status":"ok","timestamp":1697120059581,"user_tz":-390,"elapsed":316,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"7ef3ca81-ecc9-408f-83d3-ab098d89f531"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["normalizeRows(x) = [[0.         0.6        0.8       ]\n"," [0.13736056 0.82416338 0.54944226]]\n"]}]},{"cell_type":"code","source":["test = np.linalg.norm(x, axis=1, keepdims=True)\n","print(test)\n","print(test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTubC7-k44cS","executionInfo":{"status":"ok","timestamp":1697120063704,"user_tz":-390,"elapsed":341,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"00faead8-d9dc-4197-bad2-961a85ad8e57"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[[5.        ]\n"," [7.28010989]]\n","(2, 1)\n"]}]},{"cell_type":"code","source":["a = 0+ 9  + 16\n","b = 1+ 36 + 16"],"metadata":{"id":"aeUIbqoy5BJq","executionInfo":{"status":"ok","timestamp":1697120072252,"user_tz":-390,"elapsed":354,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(np.sqrt(a))\n","print(np.sqrt(b))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J96nEk0Y5sPr","executionInfo":{"status":"ok","timestamp":1697120075013,"user_tz":-390,"elapsed":3,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"b887f9ee-90a0-438e-b415-287f9b3a0067"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["5.0\n","7.280109889280518\n"]}]},{"cell_type":"markdown","source":["<a name='ex-7'></a>\n","### Exercise 7 - softmax\n","Implement a softmax function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about softmax in the second course of this specialization.\n","\n","**Instructions**:\n","- $\\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     }$\n","\n","\\begin{align*}\n"," softmax(x) &= softmax\\left(\\begin{bmatrix}\n","    x_1  &&\n","    x_2 &&\n","    ...  &&\n","    x_n  \n","\\end{bmatrix}\\right) \\\\&= \\begin{bmatrix}\n","    \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n","    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n","    ...  &&\n","    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}}\n","\\end{bmatrix}\n","\\end{align*}\n","\n","- $\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }$  \n","\n","\\begin{align*}\n","softmax(x) &= softmax\\begin{bmatrix}\n","            x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n","            x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n","            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","            x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n","            \\end{bmatrix} \\\\ \\\\&=\n"," \\begin{bmatrix}\n","    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n","    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n","    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n","\\end{bmatrix} \\\\ \\\\ &= \\begin{pmatrix}\n","    softmax\\text{(first row of x)}  \\\\\n","    softmax\\text{(second row of x)} \\\\\n","    \\vdots  \\\\\n","    softmax\\text{(last row of x)} \\\\\n","\\end{pmatrix}\n","\\end{align*}"],"metadata":{"id":"Uo_2wSaY6fBJ"}},{"cell_type":"code","source":["def softmax(x):\n","\n","    x_exp = np.exp(x)\n","    x_sum = np.sum(x_exp, axis=1,keepdims=True) # add the values of all columns in the same row, axis=1\n","    s = x_exp/x_sum\n","\n","\n","    return s"],"metadata":{"id":"n0S53VZB5uab","executionInfo":{"status":"ok","timestamp":1697120297943,"user_tz":-390,"elapsed":499,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["t_x = np.array([[9, 2, 5, 0, 0],\n","                [7, 5, 0, 0 ,0]])\n","print(\"softmax(x) = \" + str(softmax(t_x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tEkw6Rw6UwS","executionInfo":{"status":"ok","timestamp":1697120301600,"user_tz":-390,"elapsed":421,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"bc43ecf8-3dac-4f30-931f-60f71a8bdd88"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n","  1.21052389e-04]\n"," [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n","  8.01252314e-04]]\n"]}]},{"cell_type":"code","source":["def L1(yhat, y):\n","\n","\n","    loss = np.sum(np.abs(y-yhat))\n","\n","    return loss"],"metadata":{"id":"m1bOtVC8672P","executionInfo":{"status":"ok","timestamp":1697120344433,"user_tz":-390,"elapsed":358,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["<a name='ex-9'></a>\n","### Exercise 9 - L2\n","Implement the numpy vectorized version of the L2 loss. There are several way of implementing the L2 loss but you may find the function np.dot() useful. As a reminder, if $x = [x_1, x_2, ..., x_n]$, then `np.dot(x,x)` = $\\sum_{j=0}^n x_j^{2}$.\n","\n","- L2 loss is defined as $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"],"metadata":{"id":"g2PUhaBh7Q2F"}},{"cell_type":"code","source":["\n","def L2(yhat, y):\n","\n","\n","\n","    loss = np.square(y-yhat).sum()\n","\n","    return loss"],"metadata":{"id":"xNtqAKda7Hni","executionInfo":{"status":"ok","timestamp":1697120375890,"user_tz":-390,"elapsed":2,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["yhat = np.array([.9, 0.2, 0.1, .4, .9])\n","y = np.array([1, 0, 0, 1, 1])\n","\n","print(\"L2 = \" + str(L2(yhat, y)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Cxl0Kyv7M8h","executionInfo":{"status":"ok","timestamp":1697120378596,"user_tz":-390,"elapsed":5,"user":{"displayName":"s16162 Tun Tun Win","userId":"11564446739685333224"}},"outputId":"a92d9229-07c4-4c2d-e657-45375b60c5f3"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["L2 = 0.43\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4_E8q-xR7XIp"},"execution_count":null,"outputs":[]}]}